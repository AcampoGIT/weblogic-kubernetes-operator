-----------------------------------------------------------------------------------------
setup
-----------------------------------------------------------------------------------------

  doublesync src122130 and devenv.sh
    (since we're going to use WLST to create the domain)

  mkdir -m 777 -p /scratch/k8s-dir
    (i.e. the parent directory for persistent volumes)

  make sure to get rid your old setup:
  (I had problems getting stuff to run until I got rid of this stuff)
    operator and domain namespaces
    persistent volumes
    cluster roles & cluster role bindings
    maybe /scratch/k8s_dir

  install helm & tiller
    See https://github.com/kubernetes/helm/blob/master/docs/install.md

-----------------------------------------------------------------------------------------
how to run demo2
-----------------------------------------------------------------------------------------

  cd demo2

  mkdir generated # the scripts need to be improved to do this!

  helm install ../kit/charts/kubernetes-cluster --name demo-kubernetes-cluster --values kubernetes-cluster-values.yaml
  helm status demo-kubernetes-cluster

  # something about certificate generation ... ?
  helm install ../kit/charts/operator --name demo-operator --values operator-values.yaml
  helm status demo-operator

  helm install ../kit/charts/domains-ns --name demo-domains-ns --values domains-ns-values.yaml
  #helm upgrade --values domains-ns-values.yaml demo-domains-ns ../kit/charts/domains-ns
  helm status demo-domains-ns

  # can this move to a helm chart?
  kubectl -n demo-d-ns create secret generic demo2-domain-uid-domain-creds --from-literal=username=weblogic --from-literal=password=welcome1
  mkdir -p /scratch/k8s-dir/demo2-domain-uid/domain-logs
  create-domain-home.sh
  #from Tom Barnes: if running on a hosted linux box (macs don't need this):
  #  /usr/local/packages/aime/ias/run_as_root "find /scratch/k8s-dir/ -name '*' | xargs chown 1000"
  #  /usr/local/packages/aime/ias/run_as_root "find /scratch/k8s-dir/ -name '*' | xargs chgrp 1000"

  helm install ../kit/charts/domain --name demo2-domain --values domain-values.yaml
  #helm upgrade --values domain-values.yaml demo2-domain ../kit/charts/domain
  helm status demo2-domain

  # TBD - something about creating the config map containing the domain-specific sit config customizations
  # and passing the name of that config map into the sit config stuff below ...

  ../kit/runtime/simulate-operator-introspect-domain.sh demo-d-ns demo2-domain-uid default

  ../kit/runtime/simulate-operator-generate-sitcfg.sh demo-d-ns demo2-domain-uid default

  ../kit/runtime/simulate-operator-start-admin-server.sh demo-d-ns demo2-domain-uid debug default default demo2-domain as 7100

  ../kit/runtime/simulate-operator-start-managed-server.sh demo-d-ns demo2-domain-uid debug default default demo2-domain as 7100 ms1 8100
  ../kit/runtime/simulate-operator-stop-managed-server.sh demo-d-ns demo2-domain-uid debug default ms1

  ../kit/runtime/simulate-operator-stop-admin-server.sh demo-d-ns demo2-domain-uid debug default as

  ../kit/runtime/simulate-operator-remove-sitcfg.sh demo-d-ns demo2-domain-uid default

  helm delete --purge demo2-domain

  kubectl delete secret -n demo-d-ns demo2-domain-uid-domain-creds
  #from Tom Barnes: if running on a hosted linux box (macs don't need this):
  #  /usr/local/packages/aime/ias/run_as_root "find /scratch/k8s-dir/ -name '*' | xargs chmod 777"
  rm -rf /scratch/k8s-dir/demo2-domain-uid

  helm delete --purge demo-domains-ns

  helm delete --purge demo-operator

  helm delete --purge demo-kubernetes-cluster

-----------------------------------------------------------------------------------------
poc source files
-----------------------------------------------------------------------------------------

  demo2/
    uses offline wlst to create a domain with a configured cluster
    uses a domain persistent volume
    uses helm to configure everything

    kubernetes-cluster-values.yaml
      - helm configuration settings for setting up the kubernets cluster kubernetes resources

    operator-values.yaml
      - helm configuration settings for creating the operator kubernetes resources

    domains-ns-values.yaml
      - helm configuration settings for creating the domains namespace kubernetes resources

    domain-values.yaml
      - helm configuration settings for creating the domain kubernetes resources

    create-domain-home.sh
      - shell script that uses offline wlst to configure a domain home with a configured cluster

-----------------------------------------------------------------------------------------
poc generated files
-----------------------------------------------------------------------------------------

    demo2/generated/

        domain-home
          - contains the generated domain, before its pathnames have been patched
          - this means you can 'cd' there and run startWeblogicServer.sh
          - it also means that it cannot be directly used by a pod since the
            pathnames in the generated files are based on the shell that ran
            create-domain-home.sh, instead of the ones that are needed in a pod

    /scratch/k8s-dir/demo2-domain-uid
      contains the persistent volumes for demo2's domain

      domain-logs/
         - contains the domain, node manager and server logs

      domain-home/
        - contains the domain home that the pods use
        - the pathnames in the files have been patched so that the pods can use them
          (e.g. domain home, java home and mw home have been changed to the values
          that should be used inside the pod)

-----------------------------------------------------------------------------------------
todo
-----------------------------------------------------------------------------------------

pass thru customizations needed to create the sit cfg from user thru to
sit cfg generator (even though it won't pay attention to them yet)

demo2-domain-crd (roughly)

  domainUID: demo2-domain-uid

  domainIntrospector: demo2-domain-uid-default-domain-introspector-cm

  serverDefaults:
    domainCustomizations:  demo2-domain-uid-domain-customizations-cm
    sitConfigGenerator:    demo2-domain-uid-default-sitcfg-generator-cm 
    serverPodTemplate:     demo2-domain-uid-default-managed-server-pod-template-cm
    serverServiceTemplate: demo2-domain-uid-default-managed-server-service-template-cm

  adminServer:
    serverPodTemplate:       demo2-domain-uid-debug-admin-server-pod-template-cm
    serverServiceTemplate:   demo2-domain-uid-default-admin-server-service-template-cm
    serverT3ServiceTemplate: demo2-domain-uid-default-admin-server-t3-service-template-cm

possible formats for having the customer specify domain config property overridesA:

properties:

domain.server.name.as.list-address:abcd
domain.server.name.as.list-port:7001

yaml:

domain:
  server:
    name:as
    listen-address: abcd
    listen-port: 7001

make prometheus annotations optional?

try to make a template for most of the pod stuff?






overall

cluster side operator setup
  helm chart
  vars:
    elkEnabled

operator setup
  helm chart
  vars:
    externally generated certs
    most of the stuff from the old operator inputs file

domains namespace setup
  helm chart
  don't need much - mostly a namespace name

domain setup
  lots here

domain introspection
  v.s. configuring admin server name & port
  done in offline wlst in a pod w/ access to the domain home
  also does domain validation so we can tell if the operator can handle the domain

sitcfg generation
  done in offline wlst in a pod w/ access to the domain home
  need a way for the customer to add customizations
  results in a config map (with a sit cfg file) that gets mounted into the server pod

domain.values
  non-config-xml info about the domain
  templates for pods, services, ...

domain custom resource
  lifecycle rules for servers & clusters
  pointers to the templates for creating k8s artifacts


need specs
  architecture
  functional - i.e. what a customer sees

need to implement

need wlst / jython guru
  best practices
  how do we test it?

need a helm guru
  best practices
    docs
    values validation
  slots for anything we want tweakable
    e.g. add volumes, tweak timing / retry params, add labels, ...
    or should we encourage customers to copy our helm charts & tweak? (probably a bad idea)
  how do we test them since they have a lot of conditional code?
    --dry-run ?
    require k8s & look at artifacts?

naming conventions
  so that templates, ... don't collide with servers

need a backwards compat and rollout strategy

how about
  customers must create new domains using our new mechanims
    we'll need to give at least doc guidelines
  all new operator/domain config - won't work w/ old configs, old input files
  all new operator runtime - won't work w/ old domain

phase1
  build new infra for configuring artifacts, helm based, independent of old create scripts, artifacts, inputs files
  simulate operator runtime w/ scripts

phase2
  build new operator runtime (i.e. a different image) that only handles new artifacts

phase3
  cut over from old operator to new operator

i.e. I don't think we can get there incrementally easily

---------------


helm links
  https://github.com/kubernetes/helm/blob/master/docs
  https://github.com/kubernetes/helm/tree/master/docs/examples
  https://godoc.org/text/template
  https://godoc.org/github.com/Masterminds/sprig
  https://github.com/sapcc/openstack-helm/tree/master
  https://github.com/kubernetes/helm/blob/master/docs/charts_tips_and_tricks.md
  https://docs.helm.sh/chart_template_guide/#../charts
  https://docs.helm.sh/chart_template_guide/#the-chart-template-developer-s-guide
  https://github.com/Masterminds/sprig/blob/master/docs/dicts.md
  https://github.com/kubernetes/charts/blob/master/stable/traefik
  https://github.com/kubernetes/helm/blob/master/docs/examples/nginx

minimum
=======

domain-crd.yaml
---------------
domainUID: demo2-domain-uid

domain-values.yaml
------------------
operatorNamespace: demo-o-ns
domainsNamespace: demo-d-ns
domainUID: demo2-domain-uid
domainLogsPersistentVolumeDir: /scratch/k8s-dir/demo2-domain-uid/domain-logs
weblogicImage: myimage
weblogicImagePullPolicy: IfNotPresent
weblogicDomainCredentialsSecretName: demo2-domain-uid-domain-creds







put domain home on pv
=====================

domain-crd.yaml
---------------
domainUID: demo2-domain-uid

domain-values.yaml
------------------
minimum plus:

weblogicImage: store/oracle/weblogic:12.2.1.3
extraVolumeMounts:
- name: weblogic-domain-home-storage-volume
  mountPath: /domain-home
extraVolumes:
- name: weblogic-domain-home-storage-volume
  persistentVolumeClaim:
    claimName: demo2-domain-uid-weblogic-domain-home-pvc
extraResources:
- kind: PersistentVolume
  apiVersion: v1
  metadata:
    labels:
      weblogic.domainUID: demo2-domain-uid
      weblogic.resourceVersion: domain-v1
    name: demo2-domain-uid-weblogic-domain-home-pv
  spec:
    accessModes:
    - ReadWriteMany
    capacity:
      storage: 5Gi
    claimRef:
      apiVersion: v1
      kind: PersistentVolumeClaim
      name: demo2-domain-uid-weblogic-domain-home-pvc
      namespace: demo-d-ns
    hostPath:
      path: /scratch/k8s-dir/demo2-domain-uid/domain-home
      type: ""
    persistentVolumeReclaimPolicy: Retain
    storageClassName: demo2-domain-uid-weblogic-domain-home-storage-class
- kind: PersistentVolumeClaim
  apiVersion: v1
  metadata:
    labels:
      weblogic.domainUID: demo2-domain-uid
      weblogic.resourceVersion: domain-v1
    name: demo2-domain-uid-weblogic-domain-home-pvc
    namespace: demo-d-ns
  spec:
    accessModes:
    - ReadWriteMany
    resources:
      requests:
        storage: 5Gi
    storageClassName: demo2-domain-uid-weblogic-domain-home-storage-class
    volumeName: demo2-domain-uid-weblogic-domain-home-pv



turn on debugging for just the admin server
===========================================

domain-crd.yaml
---------------
domainUID: demo2-domain-uid
adminServer:
  podTemplate: debug

domain-values.yaml
------------------
minimum plus:

customAdminServerPodTemplates:
  debug:
    extraEnvVars:
    - debugEnabled: true



automatically switch the domain to a new image name
===================================================

domain-crd.yaml
---------------
domainUID: demo2-domain-uid

domain-values.yaml
------------------
minimum plus:
weblogicImage: v2image
(i.e. just change the image name - the operator will notice the stale pods
and gradually replace them)




manually switch the domain to a new image name
(i.e. customer controlled rollout)
===============================================

domain-crd.yaml
---------------
domainUID: demo2-domain-uid
adminServer:
  podTemplate: v2
clusters:
  cluster1:
    servers:
      server2:
        podTemplate: v2

domain-values.yaml
------------------
minimum plus:

weblogicImage: v1image

customPodTemplates:
  v2:
    weblogicImage: v2image

customAdminServerPodTemplates:
  v2:
    podTemplate: v2
    extraEnvVars:
    - debugEnabled: true

customManagedServerPodTemplates:
  v2:
    podTemplate: v2
    extraEnvVars:
    - debugEnabled: true
